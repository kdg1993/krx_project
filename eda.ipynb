{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import warnings\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller, kpss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korean font\n",
    "from matplotlib import font_manager, rc\n",
    "try:\n",
    "    font_path = \"C:/Windows/Fonts/malgun.TTF\"\n",
    "    Kfont = font_manager.FontProperties(fname=font_path).get_name()\n",
    "    rc('font', family=Kfont)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Fix minus presentation\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date_inv(df):\n",
    "    try:\n",
    "        df[\"날짜\"] = pd.to_datetime(df[\"날짜\"], format = \"%Y년 %m월 %d일\")\n",
    "        df = df.sort_values(by = \"날짜\", ascending=True)\n",
    "        df.set_index(\"날짜\", inplace=True)\n",
    "    except:\n",
    "        df['일자'] = pd.to_datetime(df['일자'], format='')\n",
    "        df = df.sort_values(by = \"일자\", ascending=True)\n",
    "        df = df.rename(columns={'일자': '날짜'})\n",
    "        df.set_index(\"날짜\", inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def to_numeric_inv(df):\n",
    "    try:\n",
    "        df[\"종가\"] = df[\"종가\"].replace(\",\", \"\")\n",
    "        df[\"종가\"] = pd.to_numeric(df[\"종가\"])\n",
    "    except:\n",
    "        df[\"종가\"] = df[\"종가\"].str.replace(\",\", \"\")\n",
    "        df[\"종가\"] = pd.to_numeric(df[\"종가\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "def dtype_chg(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return to_date_inv(to_numeric_inv(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get carbon credit data\n",
    "path_kau19 = 'data/external_data/KAU19-22/KAU19.csv'\n",
    "path_kau20 = 'data/external_data/KAU19-22/KAU20.csv'\n",
    "\n",
    "# Get data path from local directory\n",
    "path_brent_crude_future = 'data/external_data/Features/브렌트유 선물 내역.csv'\n",
    "path_natural_gas = 'data/external_data/Features/천연가스 선물 내역.csv'\n",
    "path_iron = 'data/external_data/Features/철광석 내역.csv'\n",
    "path_coal_future = 'data/external_data/Features/Newcastle Coal Futures 내역.csv'\n",
    "path_usd_krw = 'data/external_data/Features/USD_KRW 내역.csv'\n",
    "path_wti_crude_future = 'data/external_data/Features/WTI유 선물 내역.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load carbon credit dataset\n",
    "df_kau19 = pd.read_csv(path_kau19, encoding='euc-kr', index_col=0)\n",
    "df_kau20 = pd.read_csv(path_kau20, encoding='euc-kr', index_col=0)\n",
    "\n",
    "# Load dataset\n",
    "df_brent_crude_fut = pd.read_csv(path_brent_crude_future).dropna()\n",
    "df_natural_gas = pd.read_csv(path_natural_gas).dropna()\n",
    "df_iron = pd.read_csv(path_iron, encoding='utf-8').dropna()\n",
    "df_coal_fut = pd.read_csv(path_coal_future, encoding='utf-8').dropna()\n",
    "df_usd_krw = pd.read_csv(path_usd_krw).dropna()\n",
    "df_wti_crude_fut = pd.read_csv(path_wti_crude_future).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check KAU data set\n",
    "df_kau19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check brent crude oil future data\n",
    "df_brent_crude_fut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple dtype change : date to datetime & Close price comma fix\n",
    "df_kau19 = dtype_chg(df_kau19)\n",
    "df_kau20 = dtype_chg(df_kau20)\n",
    "\n",
    "df_brent_crude_fut = dtype_chg(df_brent_crude_fut)\n",
    "df_natural_gas = dtype_chg(df_natural_gas)\n",
    "df_iron = dtype_chg(df_iron)\n",
    "df_coal_fut = dtype_chg(df_coal_fut)\n",
    "df_usd_krw = dtype_chg(df_usd_krw)\n",
    "df_wti_crude_fut = dtype_chg(df_wti_crude_fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat close price of all time series data\n",
    "df_tot = pd.concat(\n",
    "    [\n",
    "        df_kau19['종가'],\n",
    "        df_kau20['종가'],\n",
    "        df_brent_crude_fut['종가'],\n",
    "        df_natural_gas['종가'],\n",
    "        df_iron['종가'],\n",
    "        df_coal_fut['종가'],\n",
    "        df_usd_krw['종가'],\n",
    "        df_wti_crude_fut['종가'],\n",
    "],\n",
    "axis=1)\n",
    "\n",
    "tot_col_nm = [\n",
    "        'kau19',\n",
    "        'kau20',\n",
    "        'brent_crude_fut',\n",
    "        'natural_gas',\n",
    "        'iron',\n",
    "        'coal_fut',\n",
    "        'usd_krw',\n",
    "        'wti_crude_fut',\n",
    "    ]\n",
    "\n",
    "df_tot.columns = tot_col_nm\n",
    "\n",
    "df_tot.head()\n",
    "df_kau19.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split total DataFrame by KAU\n",
    "df_19 = df_tot.drop(columns=['kau20'])\n",
    "df_20 = df_tot.drop(columns=['kau19'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly temporal smoothing\n",
    "df_19 = df_19.resample('w').mean()\n",
    "df_20 = df_20.resample('w').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign temporal restricition\n",
    "df_19 = df_19[(df_19.index > pd.Timestamp('2018-12-31')) & (df_19.index < pd.Timestamp('2021-01-01'))]\n",
    "df_20 = df_20[(df_20.index > pd.Timestamp('2019-12-31')) & (df_20.index < pd.Timestamp('2022-01-01'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check temporal restriction and smoothing\n",
    "df_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing value of each column and drop missing\n",
    "def fill_missing_and_visualize(df: pd.DataFrame, df_nm=None, visualize=True) -> pd.DataFrame:\n",
    "    df_fill = df.interpolate(limit_are='outside', limit=10)\n",
    "    df_fill_n_drop = df_fill.dropna()\n",
    "\n",
    "    if visualize:\n",
    "        ax_raw = msno.matrix(df, figsize=(12, 6))\n",
    "        ax_raw.set_title(f'[{df_nm}] Missing value before drop and fill na', fontsize=20)\n",
    "\n",
    "        ax_fill = msno.matrix(df_fill, figsize=(12, 6))\n",
    "        ax_fill.set_title(f'[{df_nm}] Missing value After fill na', fontsize=20)\n",
    "\n",
    "        ax_fill_n_drop = msno.matrix(df_fill_n_drop, figsize=(12, 6))\n",
    "        ax_fill_n_drop.set_title(f'[{df_nm}]Missing value After fill and drop na', fontsize=20)\n",
    "\n",
    "    return df_fill_n_drop\n",
    "\n",
    "df_19 = fill_missing_and_visualize(df_19, 'KAU-19')\n",
    "df_20 = fill_missing_and_visualize(df_20, 'KAU-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot - Check data by simple line plot\n",
    "def viz_line_by_col(df):\n",
    "    num_col = len(df.columns)\n",
    "\n",
    "    df.plot(\n",
    "        subplots=True, \n",
    "        layout=(int(np.ceil(num_col*2/3)), int(np.ceil(num_col*1/3))),\n",
    "        figsize=(2*int(np.ceil(num_col*2/3)), 4*int(np.ceil(num_col*1/3))),\n",
    "        )\n",
    "\n",
    "for df in [df_19, df_20]:\n",
    "    viz_line_by_col(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot - Log transformation for scaling and visualization\n",
    "def log_transform_n_viz(df, visualize=True):\n",
    "    df_log_transformed = df.applymap(np.log)\n",
    "    num_col = len(df_log_transformed.columns)\n",
    "\n",
    "    if visualize:\n",
    "        df_log_transformed.plot(\n",
    "        subplots=True, \n",
    "        layout=(int(np.ceil(num_col*2/3)), int(np.ceil(num_col*1/3))),\n",
    "        figsize=(2*int(np.ceil(num_col*2/3)), 4*int(np.ceil(num_col*1/3))),\n",
    "        )\n",
    "    \n",
    "    return df_log_transformed\n",
    "\n",
    "df_19 = log_transform_n_viz(df_19)\n",
    "df_20 = log_transform_n_viz(df_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot - visualize each time series data by lab plot and stationarity test\n",
    "def viz_stationarity_check(df:pd.DataFrame):\n",
    "    fig_lag_plot, ax_lag_plot = plt.subplots(len(df.columns), 2, figsize=(10, 5*len(tot_col_nm)))\n",
    "\n",
    "    for idx, col_nm in enumerate(df.columns):\n",
    "        \n",
    "        pd.plotting.lag_plot(df[col_nm].dropna(), ax=ax_lag_plot[idx, 0])\n",
    "        r_adf = adfuller(df[col_nm].dropna())\n",
    "        r_kpss = kpss(df[col_nm].dropna())\n",
    "        if any([r_adf[1] >= 0.05, r_kpss[1] < 0.05]):\n",
    "            diff0_stationarity = 'Non-Stationary'\n",
    "        else:\n",
    "            diff0_stationarity = 'Stationary'\n",
    "        ax_lag_plot[idx, 0].set_title(\n",
    "            f'{col_nm} || No diff\\nADF[{r_adf[1]:.2}] || KPSS [{r_kpss[1]:.2}]\\n[{diff0_stationarity}]',\n",
    "        fontsize=15, family='bold')\n",
    "\n",
    "        pd.plotting.lag_plot(df[col_nm].diff().dropna(), ax=ax_lag_plot[idx, 1])\n",
    "        r_adf = adfuller(df[col_nm].diff().dropna())\n",
    "        r_kpss = kpss(df[col_nm].diff().dropna())\n",
    "        if any([r_adf[1] < 0.05, r_kpss[1] >= 0.05]):\n",
    "            diff1_stationarity = 'Stationary'\n",
    "        else:\n",
    "            diff1_stationarity = 'Non-Stationary'\n",
    "        ax_lag_plot[idx, 1].set_title(\n",
    "            f'{col_nm} || Diff 1\\nADF[{r_adf[1]:.2}] || KPSS [{r_kpss[1]:.2}]\\n[{diff1_stationarity}]', \n",
    "        fontsize=15, family='bold')\n",
    "\n",
    "    fig_lag_plot.tight_layout()\n",
    "\n",
    "for df in [df_19, df_20]:\n",
    "    viz_stationarity_check(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference total DataFrame\n",
    "df_19 = df_19.diff().dropna()\n",
    "df_20 = df_20.diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot - Check data by simple line plot\n",
    "for df in [df_19, df_20]:\n",
    "    viz_line_by_col(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_19, df_20]\n",
    "df_nms = ['kau19', 'kau20']\n",
    "\n",
    "for df, df_nm in zip(dfs, df_nms):\n",
    "    df.to_csv(f'data/preprocessed/{df_nm}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('krx_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc46f5c985e1657c3c539eac54ec99c251674c631c2e2f1610b325c9a4de2172"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
