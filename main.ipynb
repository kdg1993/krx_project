{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import yfinance as yf\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.api import VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korean font\n",
    "from matplotlib import font_manager, rc\n",
    "try:\n",
    "    font_path = \"C:/Windows/Fonts/malgun.TTF\"\n",
    "    Kfont = font_manager.FontProperties(fname=font_path).get_name()\n",
    "    rc('font', family=Kfont)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Fix minus presentation\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed\n",
    "def fix_random_seed(seed=42):\n",
    "    import random\n",
    "    import numpy as np \n",
    "    import os\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "fix_random_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "yr_list = [19, 20, 21, 22]\n",
    "\n",
    "for yr in yr_list:\n",
    "    df = pd.read_csv(f'data/preprocessed/kau{str(yr)}.csv')\n",
    "    df.rename(columns={'날짜': 'date'}, inplace=True)\n",
    "    df.set_index('date', inplace=True)\n",
    "    df.index = df.index.astype('datetime64[ns]')\n",
    "    df_list.append(df)\n",
    "\n",
    "df_19, df_20, df_21, df_22 = df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide kau19 and kau20 by year\n",
    "df_19_pre = df_19[\n",
    "    (df_19.index > pd.Timestamp('2018-12-31')) & (df_19.index < pd.Timestamp('2020-01-01'))\n",
    "    ].rename(columns={'kau19':'kau19_19'})\n",
    "df_19_post = df_19[\n",
    "    (df_19.index > pd.Timestamp('2019-12-31')) & (df_19.index < pd.Timestamp('2021-01-01'))\n",
    "    ].rename(columns={'kau19':'kau19_20'})\n",
    "df_20_pre = df_20[\n",
    "    (df_20.index > pd.Timestamp('2019-12-31')) & (df_20.index < pd.Timestamp('2021-01-01'))\n",
    "    ].rename(columns={'kau20':'kau20_20'})\n",
    "df_20_post = df_20[\n",
    "    (df_20.index > pd.Timestamp('2020-12-31')) & (df_20.index < pd.Timestamp('2022-01-01'))\n",
    "    ].rename(columns={'kau20':'kau20_21'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple check df kau 19\n",
    "df_19_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple check df kau 20\n",
    "df_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis with VAR and Granger Causality model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_analysis(df:pd.DataFrame, var_max_lag:int=12, print_summary=False, visualize=False):\n",
    "    mdl_var = VAR(df)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            best_lag_analysis = mdl_var.select_order(var_max_lag)\n",
    "            break\n",
    "        except:\n",
    "            var_max_lag += -1\n",
    "        \n",
    "\n",
    "    if best_lag_analysis.selected_orders['aic'] == 0:\n",
    "        best_lag = var_max_lag\n",
    "    else:\n",
    "        best_lag = best_lag_analysis.selected_orders['aic']\n",
    "        \n",
    "    rslt_var = mdl_var.fit(best_lag)\n",
    "    if print_summary:\n",
    "        print(rslt_var.summary())\n",
    "\n",
    "    var_pval_tf_mat = rslt_var.pvalues.applymap(lambda x: True if x < 0.05 else False)\n",
    "\n",
    "    # plot - VAR model coefficients p-value\n",
    "    if visualize:\n",
    "        fig_var_pval, ax_var_pval = plt.subplots(1, 1, figsize=(max(4*best_lag, 8), max(6*best_lag, 12)))\n",
    "\n",
    "        heat_pval = sns.heatmap(\n",
    "            var_pval_tf_mat, \n",
    "            square=True, \n",
    "            ax=ax_var_pval, \n",
    "            annot=True,\n",
    "            annot_kws={'fontsize':15-best_lag}, \n",
    "            cbar=False,\n",
    "            linecolor='grey',\n",
    "            linewidth=0.1,\n",
    "            )\n",
    "        heat_pval.set_xticklabels(heat_pval.get_xticklabels(), fontsize=12)\n",
    "        heat_pval.set_yticklabels(heat_pval.get_yticklabels(), fontsize=12)\n",
    "        ax_var_pval.set_title(\n",
    "            'Statistical significances of VAR coefficients by p-values', \n",
    "            fontsize=15, weight='bold')\n",
    "\n",
    "        fig_var_pval.tight_layout()\n",
    "\n",
    "    return rslt_var, var_pval_tf_mat\n",
    "\n",
    "rslt, tf_mat = var_analysis(df_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze causality between two time series variables with Granger Causality Test\n",
    "def granger_analysis(df: pd.DataFrame, additional_component: list=None, print_analysis_result=False):\n",
    "    \"\"\"\n",
    "    additional_component must be a shape of\n",
    "    (feature x, feature y, time_lag)\n",
    "    \"\"\"\n",
    "    # Get p-value significance matrix\n",
    "    tf_mat = var_analysis(df, print_summary=False)[1]\n",
    "\n",
    "    selc_granger_test = []\n",
    "    main_col = tf_mat.columns[0]\n",
    "    for sig_col_info in tf_mat[tf_mat[main_col]==True].index.to_list():\n",
    "        lag, col = sig_col_info.split('.')\n",
    "        lag = lag[1:]\n",
    "        if col == main_col:\n",
    "            continue # Ignore autocorrelation\n",
    "        else:\n",
    "            selc_granger_test.append((main_col, col, int(lag)))\n",
    "\n",
    "    if print_analysis_result:\n",
    "        verbose = 1\n",
    "    else:\n",
    "        verbose = 0\n",
    "    \n",
    "    # Granger Causality Test\n",
    "    col_nms = list(set([x[0] for x in selc_granger_test]+[x[1] for x in selc_granger_test]))\n",
    "\n",
    "    df_gct = pd.DataFrame(\n",
    "        index=col_nms,\n",
    "        columns=col_nms,\n",
    "        dtype='object',\n",
    "        )\n",
    "    df_gct = df_gct.applymap(\n",
    "        lambda x: pd.Series(index=np.arange(1, int(tf_mat.index[-1].split('.')[0][1:])+1), dtype='object'))\n",
    "    df_gct.index.name='cause'\n",
    "    df_gct.columns.name='effect'\n",
    "\n",
    "    for factor_x, factor_y, time_lag in selc_granger_test:\n",
    "        # factor x -> factor y\n",
    "        if print_analysis_result:\n",
    "            print(f'\\n[{factor_x}][t-{time_lag}] -> [{factor_y}][t]', end='')\n",
    "        df_gct.loc[factor_x, factor_y][time_lag] = grangercausalitytests(\n",
    "            df[[factor_y, factor_x]],\n",
    "            maxlag=[time_lag],\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        # factor y -> factor x\n",
    "        if print_analysis_result:\n",
    "            print(f'\\n[{factor_y}][t-{time_lag}] -> [{factor_x}][t]', end='')\n",
    "        df_gct.loc[factor_y, factor_x][time_lag] = grangercausalitytests(\n",
    "            df[[factor_x, factor_y]],\n",
    "            maxlag=[time_lag],\n",
    "            verbose=verbose,\n",
    "            )\n",
    "    \n",
    "    return df_gct\n",
    "\n",
    "granger_analysis(df_20, print_analysis_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_n_granger(df, print_var_summary=False, viz_var_pval=False, print_granger_result=False):\n",
    "    rslt_var, tf_mat = var_analysis(df, print_summary=print_var_summary, visualize=viz_var_pval)\n",
    "    df_gct = granger_analysis(df, print_analysis_result=print_granger_result)\n",
    "\n",
    "    return rslt_var, tf_mat, df_gct\n",
    "\n",
    "for df in [df_19_pre, df_19_post, df_20_pre, df_20_post]:\n",
    "    var_n_granger(df, print_var_summary=False, viz_var_pval=True, print_granger_result=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('krx_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc46f5c985e1657c3c539eac54ec99c251674c631c2e2f1610b325c9a4de2172"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
